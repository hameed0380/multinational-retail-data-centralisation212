{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from data_extraction import DataExtractor\n",
    "from database_utils import DatabaseConnector\n",
    "from data_cleaning import DataCleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating instance of the DatabaseConnector\n",
    "\n",
    "Initialising the db engine and listing the tables: \n",
    "- 'legacy_store_details' \n",
    "- 'legacy_users'\n",
    "- 'orders_table'\n",
    "\n",
    "Then creating instances of extractor and data cleaning object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legacy_store_details', 'legacy_users', 'orders_table']\n"
     ]
    }
   ],
   "source": [
    "RDS_CONNECTOR = DatabaseConnector()\n",
    "RDS_CONNECTOR.init_db_engine()\n",
    "RDS_CONNECTOR.list_db_tables()\n",
    "\n",
    "lamb = DataExtractor()\n",
    "test_clean = DataCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use read_rds_table to extract the legacy users table\n",
    "\n",
    "Cleaning and uploading user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15284\n",
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "# ['legacy_store_details', 'legacy_users', 'orders_table']\n",
    "# print(lamb.read_rds_table('legacy_users'))\n",
    "\n",
    "## User Data\n",
    "retrieved_user = lamb.read_rds_table('legacy_users')\n",
    "cleaned_user = test_clean.clean_user_data(retrieved_user)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_user, 'dim_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted from pdf file using tabula\n",
    "\n",
    "Cleaning and uploading card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing jpype dependencies. Fallback to subprocess.\n",
      "No module named 'jpype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15299\n",
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "## Card Data\n",
    "retrieved_data = lamb.retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')\n",
    "#print(retrieved_data)\n",
    "cleaned_card_data = test_clean.clean_card_data(retrieved_data)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_card_data, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of stores which is 451 (retrieved from api)\n",
    "\n",
    "The extracted the store data \n",
    "\n",
    "Cleaning and uploading store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "API Response: {'statusCode': 200, 'number_stores': 451}\n",
      "     index                                            address  longitude  \\\n",
      "0        0                                                N/A        NaN   \n",
      "1        1  Flat 72W, Sally isle, East Deantown, E7B 8EB, ...   51.62907   \n",
      "2        2        Heckerstraße 4/5, 50491 Säckingen, Landshut   48.52961   \n",
      "3        3  5 Harrison tunnel, South Lydia, WC9 2BE, Westbury   51.26000   \n",
      "4        4  Studio 6, Stephen landing, South Simon, B77 2W...   53.02330   \n",
      "..     ...                                                ...        ...   \n",
      "445    445  Flat 7, Stephanie lake, Morrisside, HP8 8LH, C...   50.76306   \n",
      "446    446    Täschestraße 25, 39039 Nördlingen, Kirchlengern   52.20000   \n",
      "448    448  Studio 8, Moss mall, West Linda, M0E 6XR, High...   51.62907   \n",
      "449    449               Baumplatz 6, 80114 Kötzting, Bretten   49.03685   \n",
      "450    450  Gotthilf-Rose-Straße 7/3, 45457 Feuchtwangen, ...   50.64336   \n",
      "\n",
      "         locality    store_code  staff_numbers opening_date   store_type  \\\n",
      "0             N/A  WEB-1388012W            325   2010-06-12   Web Portal   \n",
      "1    High Wycombe   HI-9B97EE4E             34   1996-10-25        Local   \n",
      "2        Landshut   LA-0772C7B9             92   2013-04-12  Super Store   \n",
      "3        Westbury   WE-1DE82CEE             69   2014-01-02  Super Store   \n",
      "4          Belper   BE-18074576             35   2019-09-09        Local   \n",
      "..            ...           ...            ...          ...          ...   \n",
      "445         Cowes   CO-473A9FBB             94   2008-06-08  Super Store   \n",
      "446  Kirchlengern   KI-78096E8C             61   2005-05-12  Super Store   \n",
      "448  High Wycombe   HI-EEA7AE62             33   1998-05-14        Local   \n",
      "449       Bretten   BR-662EC74C             35   2020-10-17        Local   \n",
      "450    Bad Honnef   BA-B4AED588             36   2001-05-12        Local   \n",
      "\n",
      "     latitude country_code continent  \n",
      "0         NaN           GB    Europe  \n",
      "1    -0.74934           GB    Europe  \n",
      "2    12.16179           DE    Europe  \n",
      "3    -2.18750           GB    Europe  \n",
      "4    -1.48119           GB    Europe  \n",
      "..        ...          ...       ...  \n",
      "445  -1.29772           GB    Europe  \n",
      "446   8.63333           DE    Europe  \n",
      "448  -0.74934           GB    Europe  \n",
      "449   8.70745           DE    Europe  \n",
      "450   7.22780           DE    Europe  \n",
      "\n",
      "[441 rows x 11 columns]\n",
      "index               int64\n",
      "address            object\n",
      "longitude         float64\n",
      "locality           object\n",
      "store_code         object\n",
      "staff_numbers       int32\n",
      "opening_date       object\n",
      "store_type       category\n",
      "latitude          float64\n",
      "country_code     category\n",
      "continent          object\n",
      "dtype: object\n",
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "## Store data\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "headers = {'x-api-key': api_key}\n",
    "\n",
    "number_of_stores = lamb.list_number_of_stores(endpoint, headers)\n",
    "\n",
    "other = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "stores_data = lamb.retrieve_stores_data(other, headers, number_of_stores)\n",
    "cleaned_stores_data = test_clean.clean_store_data(stores_data)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_stores_data, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the the products csv from the s3 bucket\n",
    "\n",
    "Cleaning and uploading product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file from s3://data-handling-public/products.csv...\n",
      "data-handling-public products.csv\n",
      "data-handling-public products.csv\n",
      "File has sucessfully retrieved.\n",
      "Reading the CSV file into DataFrame...\n",
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "### Product Data\n",
    "s3_address_products = 's3://data-handling-public/products.csv'\n",
    "extracted_product_data = lamb.extract_from_s3(s3_address_products)\n",
    "cleaned_product_data = test_clean.clean_products_data(extracted_product_data)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_product_data, \"dim_products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use read_rds_table to extract the orders_table\n",
    "\n",
    "Cleaning and uploading orders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "## Order Data\n",
    "retrieved_orders = lamb.read_rds_table('orders_table')\n",
    "cleaned_orders = test_clean.clean_orders_data(retrieved_orders)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_orders, 'orders_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['level_0', 'index', 'date_uuid', 'first_name', 'last_name', 'user_uuid',\n",
      "       'card_number', 'store_code', 'product_code', '1', 'product_quantity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_orders.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time data json file from the s3 bucket\n",
    "\n",
    "Clean and upload the time data df to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file from https://data-handling-public/date_details.json...\n",
      "data-handling-public date_details.json\n",
      "data-handling-public date_details.json\n",
      "File has sucessfully retrieved.\n",
      "Reading the JSON file into DataFrame...\n",
      "UPLOAD SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "## Time Data\n",
    "s3_address_date = 'https://data-handling-public/date_details.json'\n",
    "extracted_date_data = lamb.extract_from_s3(s3_address_date)\n",
    "cleaned_date = test_clean.clean_date_data(extracted_date_data)\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_date, 'dim_date_times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
